{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Importing required libraries</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/tikkanr1/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/tikkanr1/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/tikkanr1/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install scikit-learn-extra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Preprocessing the data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id1</th>\n",
       "      <td>1</td>\n",
       "      <td>Anomaly detection in wide area imagery [Geniş ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2</th>\n",
       "      <td>1</td>\n",
       "      <td>Person re-identification with deep kronecker-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3</th>\n",
       "      <td>1</td>\n",
       "      <td>Crack detection in images of masonry using cnn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id4</th>\n",
       "      <td>5</td>\n",
       "      <td>Towards an energy efficient code generator for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id5</th>\n",
       "      <td>5</td>\n",
       "      <td>Sub-polyhedral scheduling using (Unit-)two-var...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    class                                               text\n",
       "id                                                          \n",
       "id1     1  Anomaly detection in wide area imagery [Geniş ...\n",
       "id2     1  Person re-identification with deep kronecker-p...\n",
       "id3     1  Crack detection in images of masonry using cnn...\n",
       "id4     5  Towards an energy efficient code generator for...\n",
       "id5     5  Sub-polyhedral scheduling using (Unit-)two-var..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "df = pd.read_csv('abstractdata5.csv', sep='\\n', header=None)\n",
    "\n",
    "#separate data columns and combine title and text\n",
    "df = df[0].str.split('#', expand=True)\n",
    "df['text'] = df[2]+df[3]\n",
    "df = df.drop([2,3], axis=1)\n",
    "\n",
    "#rename columns\n",
    "df = df.rename(columns={0:'id', 1:'class'})\n",
    "\n",
    "#set index\n",
    "df = df.set_index('id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id1</th>\n",
       "      <td>1</td>\n",
       "      <td>anomali detect wide area imageri alan anomali ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2</th>\n",
       "      <td>1</td>\n",
       "      <td>person identif deep kroneck product match grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3</th>\n",
       "      <td>1</td>\n",
       "      <td>crack detect imag masonri use cnnswhile signif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id4</th>\n",
       "      <td>5</td>\n",
       "      <td>toward energi effici code generat mobil phones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id5</th>\n",
       "      <td>5</td>\n",
       "      <td>sub polyhedr schedul use unit two variabl per ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    class                                               text\n",
       "id                                                          \n",
       "id1     1  anomali detect wide area imageri alan anomali ...\n",
       "id2     1  person identif deep kroneck product match grou...\n",
       "id3     1  crack detect imag masonri use cnnswhile signif...\n",
       "id4     5  toward energi effici code generat mobil phones...\n",
       "id5     5  sub polyhedr schedul use unit two variabl per ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprosessing\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "stemmer = nltk.stem.snowball.EnglishStemmer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "stop = nltk.corpus.stopwords.words('english')\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    #tokenize text\n",
    "    tokens = tokenizer.tokenize(row['text'])\n",
    "    \n",
    "    #filtered words list\n",
    "    filtered_words = []\n",
    "    \n",
    "    #remove non-english words and stopwords\n",
    "    for word in tokens:\n",
    "        word = word.lower()\n",
    "        if word.isascii() and word.isalpha() and word not in stop:\n",
    "            filtered_words.append(word)\n",
    "\n",
    "    #stemming\n",
    "    final_words = [stemmer.stem(word.strip()) for word in filtered_words]\n",
    "    #lemmatization\n",
    "    #final_words = [lemmatizer.lemmatize(word.strip(), pos='n') for word in filtered_words]\n",
    "    row['text'] = \" \".join(final_words)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Computing the tfidf matrix</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tfidf matrix with n_gram(1,3) and normalize data \n",
    "def tfidf(df, norml, mindf):\n",
    "    count = TfidfVectorizer(norm=norml,min_df=mindf, ngram_range=(1,3))\n",
    "    data = count.fit_transform(df['text'])\n",
    "    bag = pd.DataFrame(data.toarray(), columns=count.get_feature_names(), index=df.index)\n",
    "    return bag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Calculating the NMI score</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NMI score with geometric average as in Strehl and Ghosh\n",
    "def nmi(truelabels, predlabels):\n",
    "    nmi = metrics.normalized_mutual_info_score(truelabels, predlabels, average_method='geometric')\n",
    "    return nmi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Clustering using the Buckshot method</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buckshot method\n",
    "def buckshot(df, K, norm, minfr, affinity, linkage, seed):\n",
    "    \n",
    "    #define data\n",
    "    data = tfidf(df, norm, minfr)\n",
    "\n",
    "    #choose sqrt(Kn) samples\n",
    "    n = len(data)\n",
    "    n_samples = int(np.sqrt(K*n))\n",
    "    samples = data.sample(n_samples, random_state=seed)\n",
    "\n",
    "    #create K seeds with hierarchical clustering\n",
    "    clustering = AgglomerativeClustering(n_clusters=K, affinity=affinity, linkage=linkage)\n",
    "    clustering = clustering.fit(samples)\n",
    "\n",
    "    #concatenate word occurrence in documents for each K cluster\n",
    "    samples['results_of_clustering'] = clustering.labels_\n",
    "    concatenated = samples.groupby(samples['results_of_clustering']).sum()\n",
    "    init = concatenated.values\n",
    "    \n",
    "    #normalize word occurrence values\n",
    "    init = normalize(init, norm='l1')\n",
    "\n",
    "    #apply K-means to seeds\n",
    "    gather = KMeans(n_clusters=K, init=init, n_init=1)\n",
    "    result = gather.fit(data)\n",
    "    \n",
    "    return result.labels_, data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Comparing the clustering results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current nmi:  0.7828 current best:  l2-5-ward-euclidean 0.7828\n",
      "current nmi:  0.7616 current best:  l2-5-ward-euclidean 0.7828\n",
      "current nmi:  0.4981 current best:  l2-5-ward-euclidean 0.7828\n",
      "current nmi:  0.7616 current best:  l2-5-ward-euclidean 0.7828\n",
      "current nmi:  0.4981 current best:  l2-5-ward-euclidean 0.7828\n",
      "current nmi:  0.7616 current best:  l2-5-ward-euclidean 0.7828\n",
      "current nmi:  0.7061 current best:  l2-5-ward-euclidean 0.7828\n",
      "current nmi:  0.4722 current best:  l2-5-ward-euclidean 0.7828\n",
      "current nmi:  0.7061 current best:  l2-5-ward-euclidean 0.7828\n",
      "current nmi:  0.4722 current best:  l2-5-ward-euclidean 0.7828\n",
      "current nmi:  0.7073 current best:  l2-5-ward-euclidean 0.7828\n",
      "current nmi:  0.5342 current best:  l2-5-ward-euclidean 0.7828\n",
      "current nmi:  0.4722 current best:  l2-5-ward-euclidean 0.7828\n",
      "current nmi:  0.5342 current best:  l2-5-ward-euclidean 0.7828\n",
      "current nmi:  0.4722 current best:  l2-5-ward-euclidean 0.7828\n",
      "current nmi:  0.5342 current best:  l2-5-ward-euclidean 0.7828\n",
      "current nmi:  0.812 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.6308 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.4799 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.6308 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.4799 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.6308 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.7052 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.4644 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.7052 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.4644 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.7052 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.5245 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.4703 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.5245 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.4703 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.5245 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.8045 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.7941 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.4451 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.7941 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.4451 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.7941 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.6898 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.4522 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.6898 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.4522 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.6898 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.4793 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.4522 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.4793 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.4522 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.4793 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.7571 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.7674 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.5027 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.7674 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.5027 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.7674 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.6743 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.5027 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.6743 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.5027 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.6718 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.3247 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.5027 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.3247 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.5027 current best:  l2-4-ward-euclidean 0.812\n",
      "current nmi:  0.3247 current best:  l2-4-ward-euclidean 0.812\n"
     ]
    }
   ],
   "source": [
    "#compare buckshot with different parameters\n",
    "norms = ['l2']\n",
    "mins = [5, 4, 3, 2]\n",
    "links = ['ward', 'complete', 'average', 'single']\n",
    "all_affs = ['euclidean', 'l1', 'l2', 'manhattan', 'cosine']\n",
    "\n",
    "#define truelabels\n",
    "truelabels = df['class'].astype(int).values\n",
    "\n",
    "#df for results\n",
    "results = pd.DataFrame()\n",
    "\n",
    "#placeholder\n",
    "best = 0\n",
    "bestname = ''\n",
    "\n",
    "#SEED FOR REPRODUCING RESULTS\n",
    "seed = 11\n",
    "\n",
    "#compute NMI for all parameters\n",
    "for norm in norms:\n",
    "    for minf in mins:\n",
    "        for link in links:\n",
    "            if link == 'ward':\n",
    "                affs = ['euclidean']\n",
    "            else:\n",
    "                affs = all_affs\n",
    "            for aff in affs:\n",
    "                name = norm + '-' + str(minf) + '-' + link + '-' + aff\n",
    "                buckshot_labels, data = buckshot(df, 5, norm, minf, aff, link, seed)\n",
    "                buckshot_nmi = np.round(nmi(truelabels, buckshot_labels),4)\n",
    "                results[name] = [buckshot_nmi]\n",
    "                if buckshot_nmi > best:\n",
    "                    best = buckshot_nmi\n",
    "                    bestname = name\n",
    "                print(\"current nmi: \", str(buckshot_nmi), \"current best: \", bestname, str(best))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "l2-4-ward-euclidean        0.8120\n",
       "l2-3-ward-euclidean        0.8045\n",
       "l2-3-complete-cosine       0.7941\n",
       "l2-3-complete-euclidean    0.7941\n",
       "l2-3-complete-l2           0.7941\n",
       "                            ...  \n",
       "l2-3-complete-manhattan    0.4451\n",
       "l2-3-complete-l1           0.4451\n",
       "l2-2-single-euclidean      0.3247\n",
       "l2-2-single-l2             0.3247\n",
       "l2-2-single-cosine         0.3247\n",
       "Name: 0, Length: 64, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print results in ascending order\n",
    "results.iloc[0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Constructing the confusion matrix </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Clusters</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>346</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>185</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>253</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Clusters    0    1    2    3    4\n",
       "Classes                          \n",
       "1         346    2    1    0    4\n",
       "2           7    5  185    2    3\n",
       "3          27    0    0    3  233\n",
       "4           4  227    1    7    0\n",
       "5           5    5    5  253    7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "def confusion_matrix(truelabels,labels):\n",
    "    confusion_df = pd.DataFrame({'Classes': truelabels, 'Clusters': labels})\n",
    "    confusion_table = pd.crosstab(confusion_df['Classes'], confusion_df['Clusters'])\n",
    "    return confusion_table\n",
    "\n",
    "#truelabels\n",
    "truelabels = df['class'].astype(int).values\n",
    "\n",
    "#best buckshot clustering labels\n",
    "buckshot_labels, data = buckshot(df, 5, 'l2', 4, 'euclidean', 'ward', 11)\n",
    "\n",
    "#result matrix\n",
    "confusion_matrix(truelabels, buckshot_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Finding topics for the clusters</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id1</th>\n",
       "      <td>1</td>\n",
       "      <td>anomali detect wide area imageri alan anomali ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2</th>\n",
       "      <td>1</td>\n",
       "      <td>person identif deep kroneck product match grou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3</th>\n",
       "      <td>1</td>\n",
       "      <td>crack detect imag masonri use cnnswhile signif...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id4</th>\n",
       "      <td>5</td>\n",
       "      <td>toward energi effici code generat mobil phones...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id5</th>\n",
       "      <td>5</td>\n",
       "      <td>sub polyhedr schedul use unit two variabl per ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    class                                               text  cluster\n",
       "id                                                                   \n",
       "id1     1  anomali detect wide area imageri alan anomali ...        0\n",
       "id2     1  person identif deep kroneck product match grou...        0\n",
       "id3     1  crack detect imag masonri use cnnswhile signif...        0\n",
       "id4     5  toward energi effici code generat mobil phones...        3\n",
       "id5     5  sub polyhedr schedul use unit two variabl per ...        3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cluster'] = buckshot_labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 frequencies: \n",
      "[('use', 681), ('imag', 639), ('base', 538), ('method', 536), ('detect', 470), ('model', 463), ('propos', 450), ('comput', 396), ('vision', 365), ('learn', 364), ('system', 340), ('perform', 316), ('network', 315), ('data', 295), ('result', 292), ('object', 266), ('algorithm', 265), ('deep', 251), ('dataset', 244), ('featur', 238), ('approach', 233), ('paper', 213), ('time', 211), ('accuraci', 207), ('train', 203), ('studi', 200), ('video', 194), ('process', 192), ('applic', 191), ('visual', 187), ('track', 187), ('differ', 185), ('research', 185), ('measur', 179), ('techniqu', 178), ('improv', 177), ('inform', 173), ('develop', 169), ('estim', 160), ('evalu', 160), ('segment', 160), ('neural', 154), ('structur', 153), ('test', 150), ('camera', 149), ('show', 148), ('two', 145), ('high', 143), ('work', 141), ('present', 140), ('achiev', 136), ('recognit', 134), ('provid', 133), ('challeng', 132), ('effect', 131), ('real', 130), ('analysi', 130), ('design', 127), ('compar', 127), ('generat', 125), ('predict', 124), ('technolog', 120), ('convolut', 117), ('framework', 117), ('howev', 117), ('problem', 116), ('also', 116), ('task', 113), ('field', 113), ('human', 113), ('classif', 110), ('vehicl', 105), ('recent', 103), ('demonstr', 102), ('extract', 102), ('set', 100), ('requir', 98), ('exist', 97), ('monitor', 97), ('identifi', 96), ('state', 96), ('map', 96), ('obtain', 96), ('machin', 93), ('filter', 93), ('area', 92), ('autom', 92), ('new', 92), ('appli', 92), ('sampl', 91), ('first', 90), ('one', 89), ('experi', 88), ('sever', 87), ('import', 86), ('effici', 86), ('three', 86), ('signific', 84), ('art', 84), ('automat', 84)]\n",
      "\n",
      "Relative frequencies inside cluster (keyword, in how many docs does it appear, how much is that compared to docs in cluster): \n",
      "[('use', 288, 0.7403598971722365), ('base', 265, 0.6812339331619537), ('data', 230, 0.5912596401028277), ('method', 220, 0.5655526992287918), ('propos', 219, 0.5629820051413882), ('comput', 207, 0.532133676092545), ('result', 199, 0.5115681233933161), ('imag', 195, 0.5012853470437018), ('vision', 191, 0.4910025706940874), ('perform', 190, 0.4884318766066838), ('learn', 179, 0.4601542416452442), ('model', 177, 0.455012853470437), ('detect', 172, 0.442159383033419), ('system', 166, 0.4267352185089974), ('network', 154, 0.39588688946015427), ('deep', 136, 0.3496143958868895), ('algorithm', 126, 0.32390745501285345), ('dataset', 117, 0.30077120822622105), ('featur', 115, 0.29562982005141386), ('object', 107, 0.2750642673521851)]\n",
      "\n",
      "\n",
      "Cluster 1 frequencies: \n",
      "[('secur', 681), ('use', 403), ('base', 396), ('propos', 376), ('key', 334), ('scheme', 331), ('data', 323), ('encrypt', 318), ('protocol', 234), ('attack', 229), ('quantum', 228), ('cryptographi', 228), ('system', 228), ('comput', 226), ('algorithm', 212), ('implement', 179), ('effici', 156), ('imag', 152), ('iot', 149), ('provid', 146), ('paper', 144), ('authent', 143), ('perform', 142), ('applic', 141), ('design', 138), ('cloud', 134), ('privaci', 122), ('time', 122), ('network', 121), ('devic', 115), ('high', 115), ('techniqu', 112), ('cryptograph', 112), ('communic', 111), ('new', 106), ('method', 106), ('result', 106), ('inform', 106), ('model', 104), ('two', 102), ('also', 99), ('generat', 97), ('multipl', 96), ('user', 96), ('present', 95), ('one', 93), ('show', 92), ('number', 91), ('exist', 91), ('secret', 89), ('analysi', 89), ('compar', 87), ('problem', 85), ('share', 81), ('improv', 80), ('public', 79), ('architectur', 78), ('requir', 78), ('bit', 76), ('complex', 76), ('standard', 75), ('random', 75), ('process', 75), ('differ', 74), ('work', 73), ('chaotic', 73), ('channel', 72), ('howev', 71), ('technolog', 71), ('hardwar', 71), ('first', 67), ('resourc', 66), ('various', 65), ('evalu', 64), ('construct', 64), ('protect', 63), ('internet', 62), ('state', 62), ('develop', 61), ('integr', 59), ('power', 59), ('parti', 57), ('signatur', 57), ('storag', 57), ('novel', 56), ('mani', 55), ('low', 55), ('access', 55), ('addit', 55), ('make', 54), ('map', 54), ('lightweight', 54), ('optim', 54), ('oper', 53), ('lattic', 53), ('smart', 53), ('cost', 53), ('function', 53), ('curv', 53), ('approach', 53)]\n",
      "\n",
      "Relative frequencies inside cluster (keyword, in how many docs does it appear, how much is that compared to docs in cluster): \n",
      "[('secur', 189, 0.7907949790794979), ('use', 186, 0.7782426778242678), ('propos', 161, 0.6736401673640168), ('base', 152, 0.6359832635983264), ('key', 125, 0.5230125523012552), ('cryptographi', 117, 0.4895397489539749), ('comput', 114, 0.4769874476987448), ('system', 110, 0.4602510460251046), ('encrypt', 104, 0.4351464435146444), ('data', 100, 0.41841004184100417), ('effici', 94, 0.39330543933054396), ('scheme', 93, 0.3891213389121339), ('attack', 92, 0.38493723849372385), ('algorithm', 92, 0.38493723849372385), ('provid', 87, 0.36401673640167365), ('implement', 86, 0.3598326359832636), ('protocol', 60, 0.2510460251046025), ('quantum', 55, 0.2301255230125523), ('iot', 42, 0.17573221757322174), ('imag', 35, 0.14644351464435146)]\n",
      "\n",
      "\n",
      "Cluster 2 frequencies: \n",
      "[('databas', 651), ('data', 586), ('relat', 393), ('system', 299), ('use', 282), ('queri', 274), ('model', 202), ('base', 191), ('inform', 178), ('approach', 153), ('propos', 136), ('process', 135), ('paper', 111), ('sql', 110), ('manag', 108), ('develop', 106), ('perform', 101), ('ontolog', 101), ('result', 99), ('applic', 99), ('user', 94), ('integr', 94), ('present', 92), ('design', 92), ('method', 90), ('time', 83), ('implement', 83), ('store', 82), ('differ', 80), ('languag', 79), ('schema', 75), ('semant', 74), ('structur', 73), ('provid', 71), ('graph', 70), ('studi', 69), ('effici', 68), ('research', 68), ('algorithm', 67), ('analysi', 67), ('show', 67), ('generat', 64), ('storag', 63), ('technolog', 63), ('set', 62), ('also', 60), ('learn', 59), ('new', 58), ('web', 58), ('framework', 56), ('tool', 56), ('evalu', 55), ('map', 53), ('type', 52), ('problem', 52), ('one', 51), ('object', 50), ('valu', 49), ('larg', 48), ('sourc', 47), ('case', 47), ('requir', 47), ('exist', 47), ('test', 47), ('need', 46), ('techniqu', 46), ('comput', 45), ('access', 45), ('howev', 44), ('improv', 44), ('two', 44), ('import', 44), ('optim', 44), ('big', 43), ('task', 43), ('support', 43), ('rule', 42), ('work', 42), ('execut', 42), ('allow', 41), ('tabl', 41), ('creat', 40), ('function', 40), ('fuzzi', 40), ('natur', 40), ('well', 40), ('increas', 39), ('specif', 39), ('build', 39), ('experi', 39), ('document', 39), ('extract', 38), ('architectur', 38), ('compar', 37), ('featur', 37), ('effect', 37), ('normal', 37), ('program', 36), ('multi', 36), ('oper', 36)]\n",
      "\n",
      "Relative frequencies inside cluster (keyword, in how many docs does it appear, how much is that compared to docs in cluster): \n",
      "[('data', 190, 0.9895833333333334), ('databas', 180, 0.9375), ('relat', 157, 0.8177083333333334), ('use', 141, 0.734375), ('base', 119, 0.6197916666666666), ('system', 113, 0.5885416666666666), ('paper', 89, 0.4635416666666667), ('queri', 84, 0.4375), ('propos', 84, 0.4375), ('inform', 81, 0.421875), ('approach', 77, 0.4010416666666667), ('result', 74, 0.3854166666666667), ('model', 73, 0.3802083333333333), ('process', 73, 0.3802083333333333), ('sql', 69, 0.359375), ('perform', 65, 0.3385416666666667), ('develop', 64, 0.3333333333333333), ('applic', 64, 0.3333333333333333), ('manag', 62, 0.3229166666666667), ('ontolog', 18, 0.09375)]\n",
      "\n",
      "\n",
      "Cluster 3 frequencies: \n",
      "[('compil', 613), ('program', 367), ('use', 341), ('comput', 297), ('code', 268), ('base', 218), ('languag', 216), ('optim', 206), ('time', 195), ('system', 192), ('implement', 184), ('applic', 184), ('quantum', 181), ('paper', 176), ('perform', 170), ('graph', 169), ('algorithm', 167), ('memori', 166), ('design', 157), ('parallel', 152), ('data', 150), ('model', 144), ('present', 135), ('approach', 127), ('oper', 124), ('transform', 123), ('result', 121), ('high', 121), ('execut', 120), ('techniqu', 120), ('problem', 119), ('develop', 117), ('process', 115), ('propos', 115), ('generat', 114), ('method', 114), ('processor', 113), ('level', 110), ('show', 105), ('type', 104), ('regist', 104), ('effici', 98), ('analysi', 98), ('softwar', 98), ('improv', 97), ('theori', 96), ('loop', 96), ('reduc', 95), ('new', 94), ('c', 90), ('also', 85), ('one', 85), ('architectur', 85), ('framework', 84), ('requir', 84), ('instruct', 82), ('hardwar', 82), ('set', 80), ('two', 78), ('flow', 76), ('effect', 76), ('power', 76), ('specif', 75), ('provid', 75), ('support', 75), ('error', 75), ('gate', 74), ('schedul', 72), ('work', 70), ('run', 68), ('construct', 68), ('circuit', 68), ('tool', 67), ('depend', 67), ('dynam', 66), ('function', 65), ('achiev', 64), ('evalu', 64), ('order', 64), ('differ', 63), ('general', 63), ('state', 63), ('communic', 63), ('structur', 63), ('number', 61), ('abstract', 61), ('complex', 60), ('correct', 60), ('alloc', 60), ('inform', 59), ('network', 59), ('sourc', 58), ('automat', 56), ('proof', 56), ('allow', 56), ('test', 56), ('verifi', 55), ('semant', 54), ('formal', 53), ('benchmark', 53)]\n",
      "\n",
      "Relative frequencies inside cluster (keyword, in how many docs does it appear, how much is that compared to docs in cluster): \n",
      "[('compil', 203, 0.7660377358490567), ('use', 171, 0.6452830188679245), ('program', 155, 0.5849056603773585), ('paper', 144, 0.5433962264150943), ('comput', 132, 0.4981132075471698), ('base', 132, 0.4981132075471698), ('optim', 109, 0.41132075471698115), ('system', 102, 0.3849056603773585), ('implement', 102, 0.3849056603773585), ('code', 98, 0.36981132075471695), ('perform', 97, 0.3660377358490566), ('languag', 91, 0.3433962264150943), ('applic', 90, 0.33962264150943394), ('time', 89, 0.33584905660377357), ('algorithm', 82, 0.30943396226415093), ('design', 82, 0.30943396226415093), ('graph', 71, 0.2679245283018868), ('parallel', 62, 0.2339622641509434), ('memori', 55, 0.20754716981132076), ('quantum', 31, 0.1169811320754717)]\n",
      "\n",
      "\n",
      "Cluster 4 frequencies: \n",
      "[('robot', 839), ('control', 351), ('use', 331), ('system', 328), ('base', 212), ('perform', 201), ('model', 182), ('propos', 161), ('task', 157), ('result', 154), ('develop', 147), ('design', 145), ('method', 139), ('learn', 135), ('approach', 134), ('present', 130), ('time', 123), ('differ', 121), ('simul', 116), ('studi', 113), ('soft', 112), ('human', 112), ('environ', 110), ('work', 109), ('improv', 108), ('optim', 108), ('show', 103), ('forc', 101), ('experi', 98), ('provid', 96), ('algorithm', 95), ('dynam', 92), ('effect', 90), ('function', 90), ('sensor', 90), ('demonstr', 88), ('increas', 85), ('manipul', 85), ('evalu', 82), ('actuat', 81), ('train', 80), ('oper', 80), ('compar', 79), ('data', 79), ('requir', 78), ('object', 77), ('motion', 77), ('gait', 77), ('estim', 76), ('complex', 76), ('also', 75), ('map', 75), ('process', 74), ('applic', 73), ('paper', 72), ('stroke', 69), ('adapt', 69), ('measur', 69), ('test', 69), ('mechan', 68), ('high', 68), ('materi', 67), ('two', 66), ('autonom', 65), ('speed', 62), ('posit', 62), ('industri', 62), ('assist', 62), ('howev', 61), ('paramet', 61), ('interact', 60), ('user', 60), ('effici', 59), ('state', 59), ('inform', 59), ('real', 59), ('behavior', 59), ('technolog', 57), ('addit', 57), ('research', 57), ('experiment', 57), ('shape', 57), ('capabl', 56), ('assess', 56), ('achiev', 54), ('potenti', 54), ('three', 54), ('activ', 54), ('novel', 54), ('challeng', 53), ('comput', 52), ('includ', 52), ('well', 52), ('allow', 52), ('multi', 51), ('level', 51), ('patient', 50), ('group', 50), ('order', 50), ('observ', 49)]\n",
      "\n",
      "Relative frequencies inside cluster (keyword, in how many docs does it appear, how much is that compared to docs in cluster): \n",
      "[('robot', 193, 0.7813765182186235), ('use', 175, 0.708502024291498), ('base', 131, 0.5303643724696356), ('system', 126, 0.5101214574898786), ('perform', 120, 0.48582995951417), ('control', 116, 0.46963562753036436), ('result', 111, 0.4493927125506073), ('present', 109, 0.44129554655870445), ('propos', 96, 0.38866396761133604), ('design', 94, 0.3805668016194332), ('develop', 91, 0.3684210526315789), ('method', 89, 0.3603238866396761), ('differ', 84, 0.340080971659919), ('approach', 82, 0.3319838056680162), ('model', 80, 0.32388663967611336), ('simul', 75, 0.30364372469635625), ('time', 74, 0.29959514170040485), ('task', 69, 0.2793522267206478), ('studi', 69, 0.2793522267206478), ('learn', 53, 0.2145748987854251)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get information for topics of clusters\n",
    "from collections import Counter\n",
    "\n",
    "cluster_relative_freq = []\n",
    "\n",
    "for i in range(0,5):\n",
    "    \n",
    "    cluster = df[df['cluster']==i]\n",
    "    #print(cluster.head())\n",
    "    \n",
    "    count = Counter(\" \".join(cluster[\"text\"]).split()).most_common(100)\n",
    "    print(\"Cluster \" + str(i) + \" frequencies: \")\n",
    "    print(count)\n",
    "    topten = count[:20]\n",
    "    relative_frequency = []\n",
    "    for j in range(0,20):\n",
    "        sum_of_appearances = 0\n",
    "        for index, row in cluster.iterrows():\n",
    "            if topten[j][0] in row['text']:\n",
    "                sum_of_appearances += 1\n",
    "        relative_frequency.append((topten[j][0],sum_of_appearances,sum_of_appearances/len(cluster)))\n",
    "    cluster_relative_freq.append(relative_frequency)\n",
    "    \n",
    "    relative_frequency.sort(key=lambda x:x[2],reverse=True)\n",
    "    print(\"\\nRelative frequencies inside cluster (keyword, in how many docs does it appear, how much is that compared to docs in cluster): \")\n",
    "    print(relative_frequency)\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
